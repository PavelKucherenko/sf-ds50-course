{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Goals and objectives of the project\n",
    "Perform exploratory data analysis using the example of a dataset\n",
    "with a target variable containing the values ​​of students' scores in mathematics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Libraries import"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import seaborn as sb\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import f_oneway\n",
    "from itertools import combinations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Init"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sb.set_style(\"darkgrid\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def fillna_median(df, col):\n",
    "    \"\"\"\n",
    "    Function fills NaN values in column of df with MEDIAN value.\n",
    "    :param col: Column to replace NaN with median\n",
    "    :param df: Dataframe with specified column\n",
    "    \"\"\"\n",
    "    df.fillna({col : df[col].median()}, inplace=True)\n",
    "\n",
    "def fillna_mode(df, col):\n",
    "    \"\"\"\n",
    "    Function fills NaN values in column of df with MODE value.\n",
    "    :param col: Column to replace NaN with mode\n",
    "    :param df: Dataframe with specified column\n",
    "    \"\"\"\n",
    "    df.fillna({col : df[col].mode().iloc[0]}, inplace=True)\n",
    "\n",
    "def fill_IQR_outliers_median(df, col):\n",
    "    \"\"\"\n",
    "    Function defines and fills outliers in column of df with MEDIAN value based on IQR criterion.\n",
    "    :param col: Column to replace outliers with median\n",
    "    :param df: Dataframe with specified column\n",
    "    \"\"\"\n",
    "    q1, q3 = df[col].quantile([0.25, 0.75])\n",
    "    IQR = q3 - q1\n",
    "    df.loc[~df[col].between(q1-1.5*IQR, q3+1.5*IQR), col] = df[col].median()\n",
    "\n",
    "def show_boxplot(df, qual_col, y_col):\n",
    "    \"\"\"\n",
    "    Show boxplots for every qualitative value in specified column\n",
    "    :param df: DataFrame\n",
    "    :param qual_col: Column with qualitative values\n",
    "    :param y_col: y variable for boxplot\n",
    "    \"\"\"\n",
    "    n_unique = df[qual_col].nunique()\n",
    "    fig, ax = plt.subplots(figsize = (1.5*n_unique, 4))\n",
    "    sb.boxplot(x=qual_col, y=y_col, data=df, ax=ax)\n",
    "    plt.xticks(rotation=45)\n",
    "    ax.set_title('Boxplot for ' + qual_col)\n",
    "    plt.show()\n",
    "\n",
    "def check_ttest_diff(df, qual_col, dependent_var, p_value):\n",
    "    \"\"\"\n",
    "    Compute Student's T-test statistics between all categories in col and print results\n",
    "    :param df: DataFrame\n",
    "    :param qual_col: Qualitative column with categories in interest in specified df\n",
    "    :param dependent_var: Name of the column with dependent variable\n",
    "    :param p_value: Desired p-value threshold\n",
    "    :return: Test result for specified column:\n",
    "                True - if T-test was passed\n",
    "                       (there IS statistically significant differences within column)\n",
    "                False - if T-test was failed\n",
    "                        (there IS NO statistically significant differences within column)\n",
    "    \"\"\"\n",
    "    categories = df[qual_col].unique()\n",
    "    cat_combinations = list(combinations(categories, 2))\n",
    "    n_cat = len(cat_combinations)\n",
    "    for category_pair in cat_combinations:\n",
    "        p = ttest_ind(df.loc[df[qual_col] == category_pair[0], dependent_var],\n",
    "                      df.loc[df[qual_col] == category_pair[1], dependent_var]).pvalue\n",
    "        # T-test with Bonferroni correction\n",
    "        if p <= p_value/n_cat:\n",
    "            print(f'Statistically significant differences via T-test were found for column \\'{qual_col}\\', p={p}')\n",
    "            return True\n",
    "        else:\n",
    "            print(f'NO statistically significant differences via T-test were found for column \\'{qual_col}\\', p={p}')\n",
    "\n",
    "    return False\n",
    "\n",
    "def check_anova_diff(df, qual_col, dependent_var, p_value):\n",
    "    \"\"\"\n",
    "    Compute Student's T-test statistics between all categories in col and print results\n",
    "    :param df: DataFrame\n",
    "    :param qual_col: Qualitative column with categories in interest in specified df\n",
    "    :param dependent_var: Name of the column with dependent variable\n",
    "    :param p_value: Desired p-value threshold\n",
    "    :return: Test result for specified column:\n",
    "                True - if T-test was passed\n",
    "                       (there IS statistically significant differences within column)\n",
    "                False - if T-test was failed\n",
    "                        (there IS NO statistically significant differences within column)\n",
    "    \"\"\"\n",
    "    categories = list(df[qual_col].unique())\n",
    "    f, p = f_oneway(*[df.loc[df[qual_col] == cat, dependent_var] for cat in categories])\n",
    "    if p<=p_value:\n",
    "        result = True\n",
    "        print(f'Statistically significant differences via ANOVA test were found for column \\'{qual_col}\\', F={f}, p={p}')\n",
    "    else:\n",
    "        result = False\n",
    "        print(f'NO statistically significant differences via ANOVA test were found for column \\'{qual_col}\\', F={f}, p={p}')\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data loading"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stud_df_orig = pd.read_csv('stud_math.xls')\n",
    "stud_df_orig.sample(10)\n",
    "stud_df_orig.info()\n",
    "stud_df_orig.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exploratory data analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# In general our data rather \"good\" as we can judge on its text table analysis - no strange/corrupted values,\n",
    "# so we can proceed directly with EDA\n",
    "\n",
    "# Analyze missed values in data\n",
    "missing_stat = {}\n",
    "for col in stud_df_orig.columns:\n",
    "    missing_stat[col] = round(100*stud_df_orig[col].isna().sum() / len(stud_df_orig.index), 2)\n",
    "missing_stat = dict(sorted(missing_stat.items(), key=lambda item: item[1], reverse=True))\n",
    "print('Missing value percents:')\n",
    "display(missing_stat)\n",
    "\n",
    "# Conclusion\n",
    "# Max amount of missed values - 11.39%, so in general we have enough data for EDA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fortunately our target variable \"score\" has comparably small amount of missing values (1,52%),\n",
    "# because we need to drop this records for further analysis\n",
    "stud_df = stud_df_orig.dropna(subset=['score'])\n",
    "stud_df.info()\n",
    "# now we have 389 rows in our stud_df DataFrame"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Overview of the source data. Not very informative due to number of features, but still useful\n",
    "sb.pairplot(stud_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Primary data processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Let's see on every column and preprocess them if necessary (NaN, outliers)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Column 'school'\n",
    "stud_df['school'].value_counts(dropna=False)\n",
    "# everything looks OK. We have two schools (GP and MS) and expectedly no NaN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Column 'sex'\n",
    "stud_df['sex'].value_counts(dropna=False)\n",
    "# again everything is OK."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Column 'age'\n",
    "print(stud_df['age'].value_counts(dropna=False))\n",
    "stud_df['age'].hist()\n",
    "# everything is OK. No NaN values, no outliers (from description should be between 15 and 22 and it is).\n",
    "# Wish all the data would be like this..;)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# We know that in other columns with qualitative variables there are some NaN values\n",
    "# Let's replace them with mode value in universal manner\n",
    "# (including columns without NaN is OK, they just remain unchanged)\n",
    "qualitative_cols = stud_df.select_dtypes(include='object').columns\n",
    "\n",
    "for col in qualitative_cols:\n",
    "    print('Processing column ', col.upper())\n",
    "    print(stud_df[col].value_counts(dropna=False))\n",
    "\n",
    "    fillna_mode(stud_df, col)\n",
    "\n",
    "    print(stud_df[col].value_counts(dropna=False))\n",
    "\n",
    "# Looking on the processing results we see no strange/corrupted nominal values\n",
    "# and no NaN values after substitution with mode(), so far so good"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Now process quantitative variables (excluding dependent variable 'score')\n",
    "quantitative_cols = list(stud_df.select_dtypes(include=['int64', 'float64']).columns)\n",
    "quantitative_cols.remove('score')\n",
    "\n",
    "# df for straightforward outliers processing attempt\n",
    "stud_df_outliers_test = stud_df.copy()\n",
    "\n",
    "for col in quantitative_cols:\n",
    "    print('Processing column ', col.upper())\n",
    "    print('Number of NaN in ', col, ' = ', stud_df[col].isna().sum())\n",
    "\n",
    "    fillna_median(stud_df, col)\n",
    "\n",
    "    print('Number of NaN in ', col, ' after fillna = ', stud_df[col].isna().sum())\n",
    "\n",
    "    # try process outliers in same loop\n",
    "    # plot graphs before and after !very straightforward! dealing with outliers\n",
    "    fig, axs = plt.subplots(2,2, figsize=[20,7.5], sharex='col')\n",
    "    stud_df_outliers_test[col].hist(ax=axs[0,0])\n",
    "    sb.boxplot(x=stud_df_outliers_test[col], ax=axs[0,1])\n",
    "\n",
    "    fill_IQR_outliers_median(stud_df_outliers_test, col)\n",
    "\n",
    "    stud_df_outliers_test[col].hist(ax=axs[1,0])\n",
    "    sb.boxplot(x=stud_df_outliers_test[col], ax=axs[1,1])\n",
    "    fig.suptitle(f'Plots for column {col.upper()} outliers elimination', fontsize=16)\n",
    "\n",
    "\n",
    "# Conclusion\n",
    "# Dealing with outliers of all columns in the same way via IQR threshold - not a good idea.\n",
    "# Need common sense! So let's process outliers separately for each column"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Column 'age'\n",
    "print(stud_df['age'].value_counts(dropna=False))\n",
    "# No outliers according to description (from 15 to 22)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Column 'Medu'\n",
    "print(stud_df['Medu'].value_counts(dropna=False))\n",
    "# No outliers according to description (from 0 to 4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Column 'Fedu'\n",
    "print(stud_df['Fedu'].value_counts(dropna=False))\n",
    "# There is an obvious outlier: 40.\n",
    "# Let's just guess that it should be 4.0 like others especially since 4.0 is nota mode but rather often value\n",
    "stud_df.loc[stud_df['Fedu'] == 40,'Fedu'] = 4\n",
    "print(stud_df['Fedu'].value_counts(dropna=False))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Column 'traveltime'\n",
    "print(stud_df['traveltime'].value_counts(dropna=False))\n",
    "# No outliers according to description (from 1 to 4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Column 'studytime'\n",
    "print(stud_df['studytime'].value_counts(dropna=False))\n",
    "# No outliers according to description (from 1 to 4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Column 'studytime, granular'\n",
    "print(stud_df['studytime, granular'].value_counts(dropna=False))\n",
    "# already can see the correlation in frequency with 'studytime'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Column 'failures'\n",
    "print(stud_df['failures'].value_counts(dropna=False))\n",
    "# No outliers according to description (from 0 to 3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Column 'famrel'\n",
    "print(stud_df['famrel'].value_counts(dropna=False))\n",
    "# There is an obvious outlier: -1. Replace it with median\n",
    "stud_df.loc[stud_df['famrel'] == -1,'famrel'] = stud_df['famrel'].median()\n",
    "print(stud_df['famrel'].value_counts(dropna=False))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Column 'freetime'\n",
    "print(stud_df['freetime'].value_counts(dropna=False))\n",
    "# No outliers according to description (from 1 to 5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Column 'goout'\n",
    "print(stud_df['goout'].value_counts(dropna=False))\n",
    "# No outliers according to description (from 1 to 5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Column 'health'\n",
    "print(stud_df['health'].value_counts(dropna=False))\n",
    "# No outliers according to description (from 1 to 5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Column 'absences'\n",
    "print(stud_df['absences'].value_counts(dropna=False))\n",
    "fig, axs = plt.subplots(3,1, figsize=[10,10])\n",
    "sb.histplot(x=stud_df['absences'], ax=axs[0])\n",
    "sb.boxplot(x=stud_df['absences'], ax=axs[1])\n",
    "fig.suptitle(f'Plots for column absences outliers elimination', fontsize=16)\n",
    "\n",
    "fill_IQR_outliers_median(stud_df, 'absences')\n",
    "\n",
    "sb.histplot(x=stud_df['absences'], ax=axs[2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now all columns are ready for further analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# One more global overview of the already preprocessed data. Looks better.\n",
    "sb.pairplot(stud_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Correlation analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# calculate the correlation matrix\n",
    "corr = stud_df.corr()\n",
    "# plot the heatmap\n",
    "sb.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns)\n",
    "\n",
    "# Conclusions\n",
    "# Variable 'studytime, granular' is strongly negatively correlated with 'studytime' and can be excluded.\n",
    "# Father and mother education level is rather correlated with each other"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# So exclude 'studytime, granular' column from dataset\n",
    "stud_df = stud_df.drop(columns='studytime, granular')\n",
    "stud_df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Qualitative variables analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for col in qualitative_cols:\n",
    "    show_boxplot(stud_df, col, 'score')\n",
    "\n",
    "# Conclusions\n",
    "# From the generated plots we can see that there are several qualitative variables that have similar\n",
    "# boxplots for our dependent variable score. So we should check their influence on score statistically.\n",
    "# These variables are:\n",
    "# ['sex', 'famsize', 'Pstatus', 'reason', 'famsup', 'paid', 'activity', 'nursury', 'romantic']\n",
    "# Also maybe we should consider (in some real case) merging some of the similar categories in Mjob and Fjob in one category\n",
    "# e.g. [other, health, services and at_home] for Fjob could be merged in one category (with additional stat analysis).\n",
    "# One more observation: if someone's father is a !teacher! - this someone shows much better results in math 8^)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Considering the number of unique values in qualitative variables we will use Student's T-test for variables with only 2\n",
    "# categories ['sex', 'famsize', 'Pstatus', 'famsup', 'paid', 'activities', 'nursery', 'romantic']\n",
    "# and ANOVA (ANalysis Of VAriance) for feature 'reason' which consists of 4 categories with similar boxplots"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# In general before this we should also check if our variables have Normal distribution via such tests like\n",
    "# Shapiro-Wilk Test, D’Agostino’s K^2 Test, Anderson-Darling Test and so on. But for this study case\n",
    "# let's just check our data for \"normality\" via visual Q-Q plot\n",
    "\n",
    "bin_qual_cols = ['sex', 'famsize', 'Pstatus', 'famsup', 'paid', 'activities', 'nursery', 'romantic']\n",
    "mult_qual_cols = ['reason']\n",
    "qual_cols_to_test = bin_qual_cols + mult_qual_cols\n",
    "\n",
    "for qual_col in qual_cols_to_test:\n",
    "    categories = stud_df[qual_col].unique()\n",
    "    for category in categories:\n",
    "        fig, ax = plt.subplots(1,1)\n",
    "        category_sample = stud_df.loc[stud_df[qual_col] == category, 'score']\n",
    "        sm.qqplot(category_sample.to_numpy(), ax=ax)\n",
    "        fig.suptitle(f'Q-Q plot for qual_col {qual_col}, category {category}:', fontsize=16)\n",
    "        plt.show()\n",
    "\n",
    "# Conclusion for Q-Q plots\n",
    "# Apart from the values of the initial quantiles we can say that we get rather \"linish\" plots, so\n",
    "# make assumption that our data is normally distributed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Statistical test for binary qualitative variables\n",
    "# We choose p value threshold = 0.15 (not 0.05) because we don't want to loose to much data for further processing,\n",
    "# so with 1-0.15 = 85% confidence column categories have different mean (distribution?) and probably we NEED this data\n",
    "# (tricky moment, need to be discussed with mentor)\n",
    "non_informative_ttest_cols = []\n",
    "for qual_col in bin_qual_cols:\n",
    "    if not check_ttest_diff(stud_df, qual_col, 'score', 0.15):\n",
    "        non_informative_ttest_cols.append(qual_col)\n",
    "\n",
    "# Conclusion\n",
    "# Statistically significant differences via T-test were found for some columns\n",
    "# So from potentially non informative columns (bin_qual_cols) we will keep only them.\n",
    "\n",
    "# Drop non informative columns\n",
    "print('Non informative T-test columns are: ', non_informative_ttest_cols)\n",
    "stud_df.drop(columns=non_informative_ttest_cols, inplace=True)\n",
    "stud_df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Statistical test for multicategorical qualitative variables\n",
    "# We choose p value threshold = 0.2 (not 0.05) because we don't want to loose to much data for further processing,\n",
    "# so with 1-0.15 = 85% confidence column categories have different mean (distribution?) and probably we NEED this data\n",
    "# (tricky moment, need to be discussed with mentor)\n",
    "non_informative_anova_cols = []\n",
    "for qual_col in mult_qual_cols:\n",
    "    if not check_anova_diff(stud_df, qual_col, 'score', 0.15):\n",
    "        non_informative_anova_cols.append(qual_col)\n",
    "\n",
    "# Conclusion\n",
    "# NO statistically significant differences via ANOVA test were found for our single column 'reason', F=1.63, p=0.179\n",
    "# So we can drop non informative columns (non_informative_anova_cols) from dataset\n",
    "\n",
    "# Drop non informative columns\n",
    "print('Non informative ANOVA columns are: ', non_informative_anova_cols)\n",
    "stud_df.drop(columns=non_informative_anova_cols, inplace=True)\n",
    "stud_df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Final conclusions\n",
    "\n",
    "1. Our data have relatively small amount of missed values.\n",
    "Max percentage of missed values among columns - 11.39% (Pstatus column)\n",
    "2. Outliers were found only in 3 columns (for 2 of them there was only one outlier and for column 'absences'\n",
    " there were many of them), suggesting that the data are reasonably clean.\n",
    "3. Additional column 'studytime, granular' was not informative due to perfect correlation with 'studytime'\n",
    "4. Some qualitative columns were excluded due to relatively low statistical significance\n",
    "of the 'score' values differences between their categories (but it's a matter of chosen p-value,\n",
    "we chose it conservatively)\n",
    "5. So the most important features for stud_math data finally are the following 21 columns:\n",
    "['school','sex','age','address','Medu','Fedu','Mjob','Fjob','guardian','traveltime','studytime',\n",
    "'failures','schoolsup','paid','higher','internet','romantic', 'famrel','freetime','goout','health',\n",
    "'absences','score']"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}